import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.models import Model
from keras.callbacks import ReduceLROnPlateau, EarlyStopping

# Load data
def load_data(data_dir):
    classes = os.listdir(data_dir)
    images = []
    masks = []
    labels = []

    for class_name in classes:
        class_dir = os.path.join(data_dir, class_name)
        if os.path.isdir(class_dir):
            image_subdir = os.path.join(class_dir, 'images')
            mask_subdir = os.path.join(class_dir, 'masks')

            for filename in os.listdir(image_subdir):
                if filename.endswith(".png"):
                    # Load image
                    image_path = os.path.join(image_subdir, filename)
                    if not os.path.exists(image_path):
                        continue

                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
                    image = cv2.resize(image, (128,128))
                    images.append(image)

                    # Load mask
                    mask_filename = filename
                    mask_path = os.path.join(mask_subdir, mask_filename)
                    if not os.path.exists(mask_path):
                        continue

                    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
                    mask = cv2.resize(mask, (128,128))
                    masks.append(mask)

                    # Assign label based on class name
                    labels.append(class_name)

    return np.array(images), np.array(masks), np.array(labels)

data_dir = "/content/drive/My Drive/COVID-19_Radiography_Dataset"
images, masks, labels = load_data(data_dir)

# Plot images with masks
def plot_images_with_masks(images, masks, labels, num_images=10):
    indices = np.random.choice(len(images), num_images, replace=False)
    plt.figure(figsize=(15, 6 * num_images // 5))

    for i, idx in enumerate(indices, start=1):
        plt.subplot(num_images, 6, 6 * i - 2)
        plt.imshow(images[idx])
        plt.axis('off')
        plt.title(f"Image - Label: {labels[idx]}")

        plt.subplot(num_images, 6, 6 * i - 1)
        plt.imshow(masks[idx], cmap='gray')
        plt.axis('off')
        plt.title("Mask")

        plt.subplot(num_images, 6, 6 * i)
        plt.imshow(images[idx])
        plt.imshow(masks[idx], cmap='jet', alpha=0.5)
        plt.axis('off')
        plt.title("Image with Mask")

    plt.tight_layout()
    plt.show()

plot_images_with_masks(images, masks, labels, num_images=10)

# Split data
train_images, test_images, train_masks, test_masks = train_test_split(images, masks, test_size=0.2, random_state=42)
train_images = np.array(train_images).reshape(len(train_images),128,128)
test_images = np.array(test_images).reshape(len(test_images),128,128)

# Build and compile U2-Net model
def build_u2net_lite(input_shape, num_classes=1):
    out_ch = [64, 64, 64, 64, 64, 64, 64, 64, 64, 64, 64]
    M_ch = [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]
    input_shape_with_channels = input_shape + (1,)
    model = u2net(input_shape_with_channels, out_ch, M_ch, num_classes=num_classes)
    return model

u2net_model = build_u2net_lite((128,128))
opt = Adam(learning_rate=1e-3)
u2net_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# Define callbacks
def get_callbacks():
    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)
    checkpoint = ModelCheckpoint('ChestSegmentor.hdf5', verbose=1, save_best_only=True)
    early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)
    return [reduce_lr, checkpoint, early_stop]

# Train U2-Net model
history = u2net_model.fit(train_images, train_masks, validation_split=0.2, batch_size=16, epochs=100, callbacks=get_callbacks())

# Load best model weights
u2net_model.load_weights("ChestSegmentor.hdf5")

# Generate masks
def generate_masks(model, test_images):
    masks = model.predict(test_images)
    return masks

generated_masks = generate_masks(u2net_model, test_images)

# Plot test images with generated masks
def plot_testimages_with_masks(images, masks, num_images=10):
    indices = np.random.choice(len(images), num_images, replace=False)
    plt.figure(figsize=(15, 6 * num_images // 5))

    for i, idx in enumerate(indices, start=1):
        plt.subplot(num_images, 6, 6 * i - 2)
        plt.imshow(images[idx])
        plt.axis('off')
        plt.title("Image")

        plt.subplot(num_images, 6, 6 * i - 1)
        plt.imshow(masks[idx], cmap='gray')
        plt.axis('off')
        plt.title("Mask")

        plt.subplot(num_images, 6, 6 * i)
        plt.imshow(images[idx])
        plt.imshow(masks[idx], cmap='jet', alpha=0.5)
        plt.axis('off')
        plt.title("Image with Mask")

    plt.tight_layout()
    plt.show()

plot_testimages_with_masks(test_images, generated_masks, num_images=10)

# Encode labels for classification
le = LabelEncoder()
encoded_labels = le.fit_transform(labels)
encoded_labels = to_categorical(encoded_labels, num_classes=4)
train_images, test_images, train_labels, test_labels = train_test_split(images, encoded_labels, test_size=0.2, random_state=42)
train_images = np.array(train_images).reshape(len(train_images),128,128)
test_images = np.array(test_images).reshape(len(test_images),128,128)

# Build classification model
def build_classification_model(base_model):
    u2net_base = Model(inputs=base_model.input, outputs=base_model.output)

    for layer in u2net_base.layers:
        layer.trainable = False

    flat_layer = Flatten()(u2net_base.output)
    dense_layer = Dense(256, activation='relu')(flat_layer)
    output_layer = Dense(4, activation='softmax')(dense_layer)

    classification_model = Model(inputs=base_model.input, outputs=output_layer)
    return classification_model

classification_model = build_classification_model(u2net_model)
classification_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Define callback for model checkpoint
checkpoint_filepath = 'classification_model.h5'
model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=True,
    monitor='val_accuracy',
    mode='max',
    save_best_only=True
)

# Train classification model
history = classification_model.fit(train_images, train_labels, validation_split=0.2, batch_size=16, epochs=50, callbacks=[model_checkpoint_callback])

# Evaluate model
evaluation_result = classification_model.evaluate(test_images, test_labels)
accuracy = evaluation_result[1]
print(f'Model Accuracy on Test Data: {accuracy}')

